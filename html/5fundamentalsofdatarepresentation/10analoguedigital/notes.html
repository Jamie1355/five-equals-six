<html>
	<head>
	</head>
	
	<body>
		<p>
			Analogue and digital signals are fundamentally different.<br/>
			Analogue signals are continuous; they can take an infinite number of values in any range, e.g. 1.7543, 1.00006, 32.013419.<br/>
			Digital signals are discrete; they are limited to predefined ranges and intervals, e.g. 0, 1, 2, or 0.25, 0.50, 0.75. In either of these examples 
				there is no such thing as 0.64423552 or any other value in between intervals.<br/>
			Within the context of computing, all digital signals are binary and therefore take the value 0 or 1 only.<br/>
			<br>
			It is often required to convert between digital and analogue signals.<br/>
			Devices such as microphones or cameras that take continuous real-world measurements need to convert the signal to digital form before it can before
				processed by a computer. This is perforemed by an analogue to digital converter (ADC) which operates as follows:<br/>
			The continuously varying analogue signal (which could contain any type of information) is sampled at a certain frequency. For each sample, the ADC
				records the current analogue value to a certain precision. The higher the sampling frequency, the closer the sequence of digital data is to
				the original analogue signal.
		</p>
	</body>
</html>